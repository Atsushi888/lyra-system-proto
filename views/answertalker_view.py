# views/answertalker_view.py
from __future__ import annotations

from typing import Any, Dict, MutableMapping, List
import os
import json
import streamlit as st

from auth.roles import Role  # ã„ã¾ã¯æœªä½¿ç”¨ã ãŒå°†æ¥ã®æ‹¡å¼µç”¨ã«æ®‹ã—ã¦ãŠã
from actors.actor import Actor
from actors.answer_talker import AnswerTalker
from actors.persona.persona_classes.persona_riseria_ja import Persona

LYRA_DEBUG = os.getenv("LYRA_DEBUG", "0") == "1"


class AnswerTalkerView:
    """
    AnswerTalker / ModelsAI / JudgeAI3 / ComposerAI / MemoryAI ã®ãƒ‡ãƒãƒƒã‚°ãƒ»é–²è¦§ç”¨ãƒ“ãƒ¥ãƒ¼ï¼ˆé–²è¦§å°‚ç”¨ï¼‰
    """

    TITLE = "ðŸ§© AnswerTalkerï¼ˆAIçµ±åˆãƒ†ã‚¹ãƒˆï¼‰"

    @staticmethod
    def _render_any_as_textarea(label: str, value: Any, height: int = 220) -> None:
        if isinstance(value, str):
            st.text_area(label, value=value, height=height, label_visibility="collapsed")
            return

        if isinstance(value, (dict, list)):
            st.text_area(
                label,
                value=json.dumps(value, ensure_ascii=False, indent=2),
                height=height,
                label_visibility="collapsed",
            )
            return

        st.text_area(
            label,
            value="" if value is None else str(value),
            height=height,
            label_visibility="collapsed",
        )

    # =========================================================
    # World Changeï¼ˆimportance=5ï¼‰è¡¨ç¤ºç”¨ãƒ˜ãƒ«ãƒ‘
    # =========================================================
    @staticmethod
    def _label_reason_unavailable(code: Any) -> str:
        s = "" if code is None else str(code)
        if s == "interpersonal_complexity":
            return "ðŸ¤ å¯¾äººé–¢ä¿‚ï¼ˆè¤‡åˆï¼‰"
        if s == "external_event":
            return "ðŸŒª å¤–çš„è¦å› ï¼ˆå¤©å¤‰åœ°ç•°/ä¸å¯æŠ—åŠ›ï¼‰"
        if not s:
            return "(ãªã—)"
        return f"(unknown: {s})"

    @staticmethod
    def _container_border():
        # streamlit ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³å·®ã§ container(border=...) ãŒç„¡ã„ç’°å¢ƒã§ã‚‚è½ã¨ã•ãªã„
        try:
            return st.container(border=True)
        except Exception:
            return st.container()

    @staticmethod
    def _render_world_change_records(records: List[Any]) -> None:
        wc: List[Any] = []
        for r in records:
            try:
                if int(getattr(r, "importance", 0) or 0) >= 5:
                    wc.append(r)
            except Exception:
                continue

        try:
            wc.sort(key=lambda x: getattr(x, "created_at", "") or "", reverse=True)
        except Exception:
            pass

        st.markdown("### ðŸŒ ä¸–ç•Œå¤‰åŒ–è¨˜æ†¶ï¼ˆimportance=5ï¼‰")
        if not wc:
            st.info("ä¸–ç•Œå¤‰åŒ–è¨˜æ†¶ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        for i, r in enumerate(wc, start=1):
            summary = getattr(r, "summary", "") or ""
            created_at = getattr(r, "created_at", "") or ""
            rid = getattr(r, "round_id", None)

            with AnswerTalkerView._container_border():
                st.markdown(f"**{i}. {summary}**")
                st.caption(f"created_at: {created_at} / round_id: {rid}")

                tags = getattr(r, "tags", []) or []
                if tags:
                    st.write("Tags:", ", ".join([str(x) for x in tags]))

                reasons = getattr(r, "world_change_reasons", None)
                if isinstance(reasons, list) and reasons:
                    st.write("**Triggered by:**")
                    for t in reasons[:5]:
                        st.markdown(f"- {t}")
                else:
                    rnu = getattr(r, "reason_unavailable", None)
                    st.write("**Reason unavailable:**", AnswerTalkerView._label_reason_unavailable(rnu))

                with st.expander("Source (raw)", expanded=False):
                    su = getattr(r, "source_user", "") or ""
                    sa = getattr(r, "source_assistant", "") or ""
                    if su:
                        st.markdown("**source_user:**")
                        st.text(su)
                    if sa:
                        st.markdown("**source_assistant:**")
                        st.text(sa)

    def __init__(self) -> None:
        player_name = st.session_state.get("player_name", "ã‚¢ãƒ„ã‚·")

        persona = Persona(player_name=player_name)
        self.actor = Actor("floria", persona)

        # â˜…é–²è¦§å°‚ç”¨ï¼šsession_state ã‚’ AnswerTalker ã«æ¸¡ã•ãªã„
        local_state: MutableMapping[str, Any] = {}

        self.answer_talker = AnswerTalker(
            persona,
            state=local_state,
        )

    def render(self) -> None:
        st.header(self.TITLE)

        player_name = st.session_state.get("player_name", "ã‚¢ãƒ„ã‚·")
        reply_length_mode = st.session_state.get("reply_length_mode", "auto")
        st.caption(f"ç¾åœ¨ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼å: **{player_name}**  /  ç™ºè©±é•·ã•ãƒ¢ãƒ¼ãƒ‰: **{reply_length_mode}**")

        st.info(
            "ã“ã®ç”»é¢ã§ã¯ llm_meta ã®å†…å®¹ï¼ˆsystem_prompt / emotion_override / models / judge / composer / emotion / memoryï¼‰ã‚’å‚ç…§ã§ãã¾ã™ã€‚\n\n"
            "â€» ã“ã®ç”»é¢ã‹ã‚‰ speak() ã‚„ MemoryAI.update_from_turn() ã¯å®Ÿè¡Œã—ã¾ã›ã‚“ã€‚"
        )

        llm_meta: Dict[str, Any] = st.session_state.get("llm_meta", {}) or {}

        st.subheader("ä»Šå›žä½¿ç”¨ã•ã‚ŒãŸ system_promptï¼ˆaffection / ãƒ‰ã‚­ãƒ‰ã‚­ðŸ’“åæ˜ å¾Œï¼‰")
        if "system_prompt_used" not in llm_meta:
            st.info("system_prompt_used ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ï¼ˆã‚­ãƒ¼æœªä½œæˆï¼‰")
        else:
            sys_used = llm_meta.get("system_prompt_used")
            st.caption(
                f"system_prompt_used type={type(sys_used).__name__} / "
                f"len={len(sys_used) if isinstance(sys_used, str) else '(n/a)'}"
            )
            self._render_any_as_textarea("system_prompt_used", sys_used, height=220)

        st.subheader("emotion_overrideï¼ˆMixerAI â†’ ModelsAI ã«æ¸¡ã—ãŸæ„Ÿæƒ…ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰")
        emo_override = llm_meta.get("emotion_override") or {}
        if not emo_override:
            st.info("emotion_override ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.json(emo_override)

        st.subheader("llm_meta ã«ç™»éŒ²ã•ã‚ŒãŸ AI å›žç­”ä¸€è¦§ï¼ˆmodelsï¼‰")
        models = llm_meta.get("models", {})
        if not models:
            st.info("models æƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            for name, info in models.items():
                with st.expander(f"ãƒ¢ãƒ‡ãƒ«: {name}", expanded=True):
                    status = info.get("status", "unknown")
                    text = info.get("text", "") or ""
                    usage = info.get("usage")
                    error = info.get("error")

                    st.write("- status:", status)
                    st.write("- len(text):", len(text))

                    if usage is not None:
                        st.write("- usage:", usage)

                    if error:
                        st.error(f"error: {error}")

                    if text:
                        st.markdown("**preview:**")
                        st.code(text[:1000])

        st.subheader("JudgeAI3 ã®åˆ¤å®šçµæžœï¼ˆllm_meta['judge']ï¼‰")
        judge = llm_meta.get("judge", {})
        if not judge:
            st.info("judge æƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.write(f"- status: `{judge.get('status', 'unknown')}`")
            st.write(f"- chosen_model: `{judge.get('chosen_model', '')}`")

            reason = judge.get("reason")
            if reason:
                with st.expander("é¸æŠžç†ç”±ï¼ˆreasonï¼‰", expanded=True):
                    st.write(reason)

            chosen_text = (judge.get("chosen_text") or "").strip()
            if chosen_text:
                with st.expander("æŽ¡ç”¨ãƒ†ã‚­ã‚¹ãƒˆï¼ˆchosen_textï¼‰", expanded=True):
                    st.text_area("chosen_text", value=chosen_text, height=260, label_visibility="collapsed")

        st.subheader("ComposerAI ã®æœ€çµ‚çµæžœï¼ˆllm_meta['composer']ï¼‰")
        comp = llm_meta.get("composer", {})
        if not comp:
            st.info("composer æƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.write(f"- status: `{comp.get('status', 'unknown')}`")
            st.write(f"- source_model: `{comp.get('source_model', '')}`")
            st.write(f"- mode: `{comp.get('mode', '')}`")
            st.write(f"- is_modified: `{comp.get('is_modified', False)}`")

            base_text = (comp.get("base_text") or "").strip()
            final_text = (comp.get("text") or "").strip()

            if base_text:
                with st.expander("Refiner å‰ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆbase_textï¼‰", expanded=False):
                    st.text_area("composer_base_text", value=base_text, height=260, label_visibility="collapsed")
            if final_text:
                with st.expander("æœ€çµ‚è¿”ç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆcomposer.textï¼‰", expanded=True):
                    st.text_area("composer_text", value=final_text, height=260, label_visibility="collapsed")

        st.subheader("EmotionAI ã®è§£æžçµæžœï¼ˆllm_meta['emotion']ï¼‰")
        emo = llm_meta.get("emotion") or {}
        emo_err = llm_meta.get("emotion_error")
        if emo_err:
            st.error(f"EmotionAI error: {emo_err}")

        if not emo:
            st.info("Emotion æƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.markdown(f"- æŽ¨å®š judge_mode: `{emo.get('mode', 'normal')}`")

            cols = st.columns(3)
            with cols[0]:
                st.write(f"affection: {emo.get('affection', 0.0):.2f}")
                st.write(f"arousal:   {emo.get('arousal', 0.0):.2f}")
            with cols[1]:
                st.write(f"tension:   {emo.get('tension', 0.0):.2f}")
                st.write(f"anger:     {emo.get('anger', 0.0):.2f}")
            with cols[2]:
                st.write(f"sadness:   {emo.get('sadness', 0.0):.2f}")
                st.write(f"excitement:{emo.get('excitement', 0.0):.2f}")

        st.subheader("MemoryAI ã®çŠ¶æ…‹ï¼ˆé•·æœŸè¨˜æ†¶ï¼‰")
        memory_ai = getattr(self.answer_talker, "memory_ai", None)

        if memory_ai is None:
            st.warning("AnswerTalker.memory_ai ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        persona_id = getattr(memory_ai, "persona_id", "default")
        max_records = getattr(memory_ai, "max_store_items", 0)
        storage_file = getattr(memory_ai, "file_path", "(unknown)")
        st.write(f"- persona_id: `{persona_id}`")
        st.write(f"- max_records: `{max_records}`")
        st.write(f"- storage_file: `{storage_file}`")

        try:
            records = memory_ai.get_all_records()
        except Exception as e:
            records = []
            st.warning(f"MemoryRecord ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        if not records:
            st.info("ç¾åœ¨ã€ä¿å­˜æ¸ˆã¿ã® MemoryRecord ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            self._render_world_change_records(records)
            st.markdown("---")

            st.markdown("#### ä¿å­˜æ¸ˆã¿ MemoryRecord ä¸€è¦§ï¼ˆå…¨ä»¶ï¼‰")
            for i, r in enumerate(records, start=1):
                imp = getattr(r, "importance", 0)
                summ = getattr(r, "summary", "") or ""
                summ_head = (summ[:32] + "...") if len(summ) > 32 else summ

                with st.expander(f"è¨˜æ†¶ {i}: [imp={imp}] {summ_head}", expanded=False):
                    st.write(f"- id: `{getattr(r, 'id', '')}`")
                    st.write(f"- round_id: {getattr(r, 'round_id', 0)}")
                    st.write(f"- importance: {imp}")
                    st.write(f"- created_at: {getattr(r, 'created_at', '')}")
                    tags = getattr(r, "tags", None) or []
                    st.write(f"- tags: {', '.join(tags) if tags else '(ãªã—)'}")

                    if int(imp or 0) >= 5:
                        wcr = getattr(r, "world_change_reasons", None)
                        rnu = getattr(r, "reason_unavailable", None)
                        st.markdown("**world_change:**")
                        if isinstance(wcr, list) and wcr:
                            st.write("- world_change_reasons:")
                            st.json(wcr)
                        else:
                            st.write("- reason_unavailable:", self._label_reason_unavailable(rnu))

                    st.write("**summary:**")
                    st.write(summ)

                    su = getattr(r, "source_user", "") or ""
                    sa = getattr(r, "source_assistant", "") or ""
                    if su:
                        st.write("\n**source_user:**")
                        st.text(su)
                    if sa:
                        st.write("\n**source_assistant:**")
                        st.text(sa)


def create_answertalker_view() -> AnswerTalkerView:
    return AnswerTalkerView()
