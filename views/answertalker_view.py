# views/answertalker_view.py

from __future__ import annotations

from typing import Any, Dict, List, Protocol

import os
import json
import streamlit as st

from auth.roles import Role  # ã„ã¾ã¯æœªä½¿ç”¨ã ãŒå°†æ¥ã®æ‹¡å¼µç”¨ã«æ®‹ã—ã¦ãŠã
from actors.actor import Actor
from actors.answer_talker import AnswerTalker
from personas.persona_floria_ja import Persona  # ã„ã¾ã¯ãƒ•ãƒ­ãƒ¼ãƒªã‚¢å›ºå®š


class View(Protocol):
    def render(self) -> None:
        ...


class AnswerTalkerView:
    """
    AnswerTalker / ModelsAI / JudgeAI2 / ComposerAI / MemoryAI ã®
    ãƒ‡ãƒãƒƒã‚°ãƒ»é–²è¦§ç”¨ãƒ“ãƒ¥ãƒ¼ã€‚
    """

    TITLE = "ğŸ§© AnswerTalkerï¼ˆAIçµ±åˆãƒ†ã‚¹ãƒˆï¼‰"

    def __init__(self) -> None:
        # Actor ã¨ AnswerTalker ã‚’åˆæœŸåŒ–
        # ï¼ˆå¿…è¦ãªã‚‰å°†æ¥ã“ã“ã« persona é¸æŠ UI ã‚’ä»˜ã‘ã‚‰ã‚Œã‚‹ï¼‰
        persona = Persona()
        self.actor = Actor("floria", persona)
        self.answer_talker = AnswerTalker(persona)

    def render(self) -> None:
        st.header(self.TITLE)

        st.info(
            "ã“ã®ç”»é¢ã§ã¯ã€Actor ã«ç´ã¥ã AnswerTalker ãŒä¿æŒã—ã¦ã„ã‚‹ llm_meta ã®å†…å®¹ "
            "ï¼ˆmodels / judge / composer / memoryï¼‰ã‚’å‚ç…§ã§ãã¾ã™ã€‚\n\n"
            "â€» ã“ã®ç”»é¢ã‹ã‚‰ã¯ AnswerTalker.run_models() ã‚„ MemoryAI.update_from_turn() ãªã©ã¯å®Ÿè¡Œã—ã¾ã›ã‚“ã€‚"
        )

        llm_meta: Dict[str, Any] = st.session_state.get("llm_meta", {}) or {}

        # ---- models ----
        st.subheader("llm_meta ã«ç™»éŒ²ã•ã‚ŒãŸ AI å›ç­”ä¸€è¦§ï¼ˆmodelsï¼‰")
        models = llm_meta.get("models", {})

        if not models:
            st.info("models æƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            for name, info in models.items():
                with st.expander(f"ãƒ¢ãƒ‡ãƒ«: {name}", expanded=True):
                    status = info.get("status", "unknown")
                    text = info.get("text", "") or ""
                    usage = info.get("usage")
                    error = info.get("error")

                    st.write("- status:", status)
                    st.write("- len(text):", len(text))

                    if usage is not None:
                        st.write("- usage:", usage)

                    if error:
                        st.error(f"error: {error}")

                    # å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚é ­ã ã‘ç¢ºèªã§ãã‚‹ã‚ˆã†ã«
                    if text:
                        st.markdown("**preview:**")
                        st.code(text[:1000])  # é•·ã™ãã‚‹ã¨å›°ã‚‹ã®ã§é ­ã ã‘è¡¨ç¤º

        # ---- judge ----
        st.subheader("JudgeAI2 ã®åˆ¤å®šçµæœï¼ˆllm_meta['judge']ï¼‰")
        judge = llm_meta.get("judge", {})
        if not judge:
            st.info("judge æƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.write(f"- status: `{judge.get('status', 'unknown')}`")
            st.write(f"- chosen_model: `{judge.get('chosen_model', '')}`")

            reason = judge.get("reason")
            if reason:
                with st.expander("é¸æŠç†ç”±ï¼ˆreasonï¼‰", expanded=True):
                    st.write(reason)

            chosen_text = (judge.get("chosen_text") or "").strip()
            if chosen_text:
                with st.expander("æ¡ç”¨ãƒ†ã‚­ã‚¹ãƒˆï¼ˆchosen_textï¼‰", expanded=True):
                    st.text_area(
                        "chosen_text",
                        value=chosen_text,
                        height=260,
                        label_visibility="collapsed",
                    )

            # â–¼ å€™è£œãƒ¢ãƒ‡ãƒ«ï¼‹ã‚¹ã‚³ã‚¢ä¸€è¦§
            raw_candidates = judge.get("candidates") or []
            with st.expander("å€™è£œãƒ¢ãƒ‡ãƒ«ä¸€è¦§ï¼ˆcandidates / scoresï¼‰", expanded=False):
                if isinstance(raw_candidates, dict):
                    # ã‚‚ã— dict å½¢å¼: {model_name: {score, text, ...}}
                    for name, info in raw_candidates.items():
                        score = info.get("score", "-")
                        preview = (info.get("text") or "")[:800]
                        st.markdown(f"### {name}  |  score = `{score}`")
                        st.write(preview)
                        st.markdown("---")
                elif isinstance(raw_candidates, list):
                    # ã‚‚ã— list å½¢å¼: [{"name":..., "score":..., "text":...}, ...]
                    for i, cand in enumerate(raw_candidates, start=1):
                        name = cand.get("name", f"cand-{i}")
                        score = cand.get("score", "-")
                        length = cand.get("length", 0)
                        preview = (cand.get("text") or "")[:800]
                        st.markdown(
                            f"### å€™è£œ {i}: `{name}`  |  score = `{score}`  |  length = {length}"
                        )
                        st.write(preview)
                        details = cand.get("details") or {}
                        if details:
                            with st.expander("details", expanded=False):
                                st.json(details)
                        st.markdown("---")
                else:
                    st.write("candidates ã®å½¢å¼ãŒæƒ³å®šå¤–ã§ã™:", type(raw_candidates))
    
        # ---- composer ----
        st.subheader("ComposerAI ã®æœ€çµ‚çµæœï¼ˆllm_meta['composer']ï¼‰")
        comp = llm_meta.get("composer", {})
        if not comp:
            st.info("composer æƒ…å ±ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.write(f"- status: `{comp.get('status', 'unknown')}`")
            st.write(f"- source_model: `{comp.get('source_model', '')}`")
            st.write(f"- mode: `{comp.get('mode', '')}`")

            summary = comp.get("summary")
            if summary:
                with st.expander("ã‚µãƒãƒªï¼ˆsummaryï¼‰", expanded=True):
                    st.text_area(
                        "composer_summary",
                        value=str(summary),
                        height=200,
                        label_visibility="collapsed",
                    )

            text = (comp.get("text") or "").strip()
            if text:
                with st.expander("æœ€çµ‚è¿”ç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆcomposer.textï¼‰", expanded=True):
                    st.text_area(
                        "composer_text",
                        value=text,
                        height=260,
                        label_visibility="collapsed",
                    )

        # ---- MemoryAI ----
        st.subheader("MemoryAI ã®çŠ¶æ…‹ï¼ˆé•·æœŸè¨˜æ†¶ï¼‰")
        memory_ctx = llm_meta.get("memory_context") or ""
        mem_update = llm_meta.get("memory_update") or {}

        # AnswerTalker ãŒæŠ±ãˆã¦ã„ã‚‹ MemoryAI ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
        memory_ai = getattr(self.answer_talker, "memory_ai", None)

        if memory_ai is None:
            st.warning("AnswerTalker.memory_ai ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            persona_id = getattr(memory_ai, "persona_id", "default")
            max_records = getattr(memory_ai, "max_store_items", 0)
            storage_file = getattr(memory_ai, "file_path", "(unknown)")
            st.write(f"- persona_id: `{persona_id}`")
            st.write(f"- max_records: `{max_records}`")
            st.write(f"- storage_file: `{storage_file}`")

            # ãƒ¡ãƒ¢ãƒªä¸€è¦§ï¼ˆMemoryAI.get_all_recordsï¼‰
            try:
                records = memory_ai.get_all_records()
            except Exception as e:
                records = []
                st.warning(f"MemoryRecord ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

            if not records:
                st.info("ç¾åœ¨ã€ä¿å­˜æ¸ˆã¿ã® MemoryRecord ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.markdown("#### ä¿å­˜æ¸ˆã¿ MemoryRecord ä¸€è¦§")
                for i, r in enumerate(records, start=1):
                    with st.expander(
                        f"è¨˜æ†¶ {i}: [imp={r.importance}] {r.summary[:32]}...",
                        expanded=False,
                    ):
                        st.write(f"- id: `{r.id}`")
                        st.write(f"- round_id: {r.round_id}")
                        st.write(f"- importance: {r.importance}")
                        st.write(f"- created_at: {r.created_at}")
                        st.write(
                            f"- tags: {', '.join(r.tags) if r.tags else '(ãªã—)'}"
                        )
                        st.write("**summary:**")
                        st.write(r.summary)
                        if r.source_user:
                            st.write("\n**source_user:**")
                            st.text(r.source_user)
                        if r.source_assistant:
                            st.write("\n**source_assistant:**")
                            st.text(r.source_assistant)

            # â–¼ å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã®è¨ºæ–­ï¼ˆJSON ãŒæœ¬å½“ã«ä½œã‚‰ã‚Œã¦ã„ã‚‹ã‹ï¼‰
            st.markdown("---")
            st.markdown("### MemoryAI ãƒ•ã‚¡ã‚¤ãƒ«è¨ºæ–­ï¼ˆJSONï¼‰")

            if st.button("è¨˜æ†¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨ºæ–­ã™ã‚‹", key="memfile_check_at"):
                path = storage_file
                st.write(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: `{path}`")

                if not path or path == "(unknown)":
                    st.error("MemoryAI.file_path ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                elif not os.path.exists(path):
                    st.error(
                        "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã¾ã ä¸€åº¦ã‚‚è¨˜æ†¶ãŒä¿å­˜ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                    )
                else:
                    st.success("ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ã¾ã™ã€‚")

                    size = os.path.getsize(path)
                    st.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: `{size}` ãƒã‚¤ãƒˆ")

                    try:
                        with open(path, "r", encoding="utf-8") as f:
                            data = json.load(f)
                    except Exception as e:
                        st.error(f"JSON ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    else:
                        if isinstance(data, list):
                            st.write(f"- JSON ã¯ãƒªã‚¹ãƒˆã§ã™ã€‚è¦ç´ æ•°: `{len(data)}`")
                            if data:
                                st.write("- å…ˆé ­3ä»¶ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
                                st.json(data[:3])
                            else:
                                st.info("ãƒªã‚¹ãƒˆã¯ç©ºã§ã™ï¼ˆè¨˜æ†¶ãŒ 0 ä»¶ã§ã™ï¼‰ã€‚")
                        else:
                            st.write(f"- JSON ã®å‹: `{type(data)}`")
                            st.json(data)

        st.subheader("llm_meta å†…ã®ãƒ¡ãƒ¢ãƒªé–¢é€£ãƒ¡ã‚¿æƒ…å ±")
        st.write(f"- memory_context:\n\n```text\n{memory_ctx}\n```")
        st.write("- memory_updateï¼ˆç›´è¿‘ã‚¿ãƒ¼ãƒ³ã®è¨˜æ†¶æ›´æ–°çµæœï¼‰:")
        st.json(mem_update)


# ===== ã“ã“ãŒé‡è¦ï¼šModeSwitcher ã‹ã‚‰å‘¼ã¶ãƒ•ã‚¡ã‚¯ãƒˆãƒª =====

def create_answertalker_view() -> AnswerTalkerView:
    """
    ModeSwitcher ã‹ã‚‰å‘¼ã¶ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°ã€‚
    """
    return AnswerTalkerView()
