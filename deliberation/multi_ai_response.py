# deliberation/multi_ai_response.py

from __future__ import annotations

from typing import Any, Dict, Optional

import streamlit as st

from components.multi_ai_display_config import MultiAIDisplayConfig
from components.multi_ai_model_viewer import MultiAIModelViewer
from components.multi_ai_judge_result_view import MultiAIJudgeResultView
from deliberation.judge_ai import JudgeAI
from deliberation.composer_ai import ComposerAI
from deliberation.participating_models import PARTICIPATING_MODELS

# deliberation/multi_ai_response.py
# ------------------------------------------------------------
# å‚åŠ AIãƒ¢ãƒ‡ãƒ«ä¸€è¦§ï¼ˆPARTICIPATING_MODELSï¼‰
# æœ¬å®šç¾©ã¯ã€AIé–“ã®å¯©è­°ãƒ»æ¯”è¼ƒã«ãŠã„ã¦ã€
# åç§°ã¨ç°¡å˜ãªèª¬æ˜ã‚’ä¸ãˆã‚‹ãŸã‚ã®é™çš„ãƒªã‚¹ãƒˆã§ã™ã€‚
# ------------------------------------------------------------

class MultiAIResponse:
    """
    ãƒãƒ«ãƒAIé–¢é€£ã®è¡¨ç¤ºã¨å¯©è­°ã‚’ã¾ã¨ã‚ã‚‹ä¸­æ ¸ã‚¯ãƒ©ã‚¹ã€‚

    å½¹å‰²:
      - llm_meta ã‹ã‚‰ models / judge ã‚’æ•´ãˆã‚‹
      - ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®å¿œç­”ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º
      - Judge ã®çµæœã‚’è¡¨ç¤º
      - ComposerAI ã‚’ä½¿ã£ã¦ã€Œãƒ™ã‚¹ãƒˆå€™è£œã€ã‚’è¨ˆç®—ã—ã€è£ç”»é¢ã§è¡¨ç¤º

    â€» v1 ã§ã¯ Lyra æœ¬ä½“ã®è¿”ç­”ã¯å¤‰æ›´ã—ãªã„ã€‚
       ã‚ãã¾ã§ãƒ‡ãƒãƒƒã‚°ï¼†å°†æ¥ã®å·®ã—æ›¿ãˆã®ãŸã‚ã®æƒ…å ±è¡¨ç¤ºã«ç•™ã‚ã‚‹ã€‚
    """

    def __init__(self) -> None:
        self.display_config = MultiAIDisplayConfig(
            initial={
                "gpt4o": "GPT-4o",
                "hermes": "Hermes",
            }
        )
        self.model_viewer = MultiAIModelViewer(self.display_config)
        self.judge_view = MultiAIJudgeResultView()
        self.judge_ai = JudgeAI()
        self.composer = ComposerAI(mode="winner_only")

    # ---- models / judge ã®ç¢ºä¿ ----
    def _ensure_models(self, llm_meta: Dict[str, Any]) -> Dict[str, Any]:
        """
        llm_meta["models"] ã‚’è¿”ã™ã€‚
        ãªã‘ã‚Œã°ç©º dict ã‚’è¿”ã™ï¼ˆä»Šã¯ Collector ã¾ã§ã¯å‘¼ã°ãªã„å‰æï¼‰ã€‚
        """
        models = llm_meta.get("models")
        if isinstance(models, dict):
            return models
        return {}

    def _ensure_judge(
        self,
        llm_meta: Dict[str, Any],
        models: Dict[str, Any],
    ) -> Optional[Dict[str, Any]]:
        """
        llm_meta["judge"] ãŒãªã‘ã‚Œã° JudgeAI ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™ã€‚
        """
        judge = llm_meta.get("judge")
        if isinstance(judge, dict):
            return judge

        if not isinstance(models, dict) or len(models) < 2:
            return None

        judge = self.judge_ai.run(llm_meta)
        return judge

    # ---- ãƒ¡ã‚¤ãƒ³æç”» ----
    def render(self, llm_meta: Dict[str, Any] | None) -> None:
        if not isinstance(llm_meta, dict) or not llm_meta:
            st.caption("ï¼ˆãƒãƒ«ãƒAIé–¢é€£ã®ãƒ¡ã‚¿æƒ…å ±ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        # models / judge ã‚’ç¢ºä¿
        models = self._ensure_models(llm_meta)
        judge = self._ensure_judge(llm_meta, models)

        # 1) å„ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”æ¯”è¼ƒ
        with st.expander("ğŸ¤ ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ", expanded=True):
            if models:
                # ã“ã“ã¯å…ƒã€…ã® MultiAIModelViewer ã® render ã«åˆã‚ã›ã‚‹
                self.model_viewer.render(models)
            else:
                st.caption("ï¼ˆmodels ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")

        # 2) Judge ã®çµæœ
        with st.expander("âš–ï¸ ãƒãƒ«ãƒAIå¯©è­°çµæœ", expanded=True):
            self.judge_view.render(judge)

        # 3) Composer ã«ã‚ˆã‚‹ã€Œãƒ™ã‚¹ãƒˆå€™è£œã€
        with st.expander("ğŸ§¬ ãƒ™ã‚¹ãƒˆå›ç­”å€™è£œï¼ˆComposerï¼‰", expanded=False):
            if not models:
                st.caption("ï¼ˆmodels ãŒãªã„ãŸã‚ã€Composer ã¯å®Ÿè¡Œã—ã¦ã„ã¾ã›ã‚“ï¼‰")
                return

            # ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹è¿”ç­”ï¼ˆã¨ã‚Šã‚ãˆãš gpt4o å„ªå…ˆï¼‰
            base_reply = ""
            if "gpt4o" in models:
                base_reply = str(models["gpt4o"].get("reply") or "")
            else:
                # å…ˆé ­ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹
                first_key = list(models.keys())[0]
                base_reply = str(models[first_key].get("reply") or "")

            # user_prompt ã¯ç¾æ®µéšã§ã¯å¿…é ˆã§ã¯ãªã„ã®ã§ç©ºã§OK
            final_info = self.composer.decide_final_reply(
                user_prompt="",
                models=models,
                judge=judge,
                base_reply=base_reply,
            )

            # llm_meta ã«ã‚‚æ ¼ç´ã—ã¦ãŠãï¼ˆå¾Œã§ä½¿ã„ãŸããªã£ãŸæ™‚ã®ãŸã‚ï¼‰
            llm_meta["composer"] = final_info

            chosen_model = final_info.get("chosen_model", "unknown")
            final_reply = final_info.get("final_reply") or "ï¼ˆå€™è£œãªã—ï¼‰"
            mode = final_info.get("mode", "unknown")

            st.markdown(f"- ãƒ¢ãƒ¼ãƒ‰: `{mode}`")
            st.markdown(f"- æ¡ç”¨å€™è£œãƒ¢ãƒ‡ãƒ«: `{chosen_model}`")
            st.markdown("**æœ€çµ‚å€™è£œãƒ†ã‚­ã‚¹ãƒˆ:**")
            st.write(final_reply)
