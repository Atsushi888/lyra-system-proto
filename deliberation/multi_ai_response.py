# deliberation/multi_ai_response.py

from __future__ import annotations
from typing import Any, Dict, Optional
import streamlit as st

from components.multi_ai_display_config import MultiAIDisplayConfig
from components.multi_ai_model_viewer import MultiAIModelViewer
from components.multi_ai_judge_result_view import MultiAIJudgeResultView
from deliberation.judge_ai import JudgeAI
from deliberation.composer_ai import ComposerAI
from deliberation.participating_models import PARTICIPATING_MODELS


class MultiAIResponse:
    """
    ãƒãƒ«ãƒAIé–¢é€£ã®è¡¨ç¤ºã¨å¯©è­°ã‚’ã¾ã¨ã‚ã‚‹ä¸­æ ¸ã‚¯ãƒ©ã‚¹ã€‚
    """

    def __init__(self) -> None:
        self.display_config = MultiAIDisplayConfig(initial={"gpt4o": "GPT-4o", "hermes": "Hermes"})
        self.model_viewer = MultiAIModelViewer(self.display_config)
        self.judge_view = MultiAIJudgeResultView()
        self.judge_ai = JudgeAI()
        self.composer = ComposerAI(mode="winner_only")

    def _ensure_models(self, llm_meta: Dict[str, Any]) -> Dict[str, Any]:
        models = llm_meta.get("models")
        if isinstance(models, dict):
            return models
        return {}

    def _ensure_judge(self, llm_meta: Dict[str, Any], models: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        judge = llm_meta.get("judge")
        if isinstance(judge, dict):
            return judge
        if not isinstance(models, dict) or len(models) < 2:
            return None
        return self.judge_ai.run(llm_meta)

    def render(self, llm_meta: Dict[str, Any] | None) -> None:
        if not isinstance(llm_meta, dict) or not llm_meta:
            st.caption("ï¼ˆãƒãƒ«ãƒAIé–¢é€£ã®ãƒ¡ã‚¿æƒ…å ±ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        models = self._ensure_models(llm_meta)
        judge = self._ensure_judge(llm_meta, models)

        with st.expander("ğŸ¤ ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ", expanded=True):
            if models:
                self.model_viewer.render(models)
            else:
                st.caption("ï¼ˆmodels ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")

        with st.expander("âš–ï¸ ãƒãƒ«ãƒAIå¯©è­°çµæœ", expanded=True):
            self.judge_view.render(judge)

        with st.expander("ğŸ§¬ ãƒ™ã‚¹ãƒˆå›ç­”å€™è£œï¼ˆComposerï¼‰", expanded=False):
            if not models:
                st.caption("ï¼ˆmodels ãŒãªã„ãŸã‚ã€Composer ã¯å®Ÿè¡Œã—ã¦ã„ã¾ã›ã‚“ï¼‰")
                return

            base_reply = models.get("gpt4o", {}).get("reply") or ""
            final_info = self.composer.decide_final_reply("", models, judge, base_reply)

            llm_meta["composer"] = final_info

            st.markdown(f"- ãƒ¢ãƒ¼ãƒ‰: `{final_info.get('mode', 'unknown')}`")
            st.markdown(f"- æ¡ç”¨å€™è£œãƒ¢ãƒ‡ãƒ«: `{final_info.get('chosen_model', 'unknown')}`")
            st.markdown("**æœ€çµ‚å€™è£œãƒ†ã‚­ã‚¹ãƒˆ:**")
            st.write(final_info.get("final_reply") or "ï¼ˆå€™è£œãªã—ï¼‰")
