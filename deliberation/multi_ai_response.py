# components/multi_ai_response.py

from __future__ import annotations

from typing import Any, Dict, Optional, List
import streamlit as st

from components.multi_ai_display_config import MultiAIDisplayConfig
from components.multi_ai_model_viewer import MultiAIModelViewer
from components.multi_ai_judge_result_view import MultiAIJudgeResultView
from deliberation.judge_ai import JudgeAI  # ãƒ‘ã‚¹ã¯ç’°å¢ƒã«åˆã‚ã›ã¦

PARTICIPATING_MODELS = {
    "gpt4o": "GPT-4o",
    "hermes": "Hermes",
}

class MultiAIResponse:
    """
    ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸ã‚¯ãƒ©ã‚¹ã€‚

    ãƒ»è¡¨ç¤ºå¯¾è±¡AIã®è¨­å®šï¼ˆMultiAIDisplayConfigï¼‰
    ãƒ»ãƒ¢ãƒ‡ãƒ«å¿œç­”ãƒ“ãƒ¥ãƒ¼ï¼ˆMultiAIModelViewerï¼‰
    ãƒ»JudgeAI ã«ã‚ˆã‚‹å¯©è­°å®Ÿè¡Œ
    ãƒ»å¯©è­°çµæœãƒ“ãƒ¥ãƒ¼ï¼ˆMultiAIJudgeResultViewï¼‰

    DebugPanel ãªã©ã®ä¸Šä½å´ã¯ã€ã“ã®ã‚¯ãƒ©ã‚¹ã« llm_meta ã‚’æ¸¡ã—ã¦
    render() ã‚’å‘¼ã¶ã ã‘ã§ã‚ˆã„ã€‚

    â€» llm_meta["models"] ãŒç„¡ã„å ´åˆã€æœ€å¾Œã® assistant ç™ºè¨€ã‹ã‚‰
       GPT-4o ã®ä»® models ã‚’çµ„ã¿ç«‹ã¦ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚æŒã¤ã€‚
    """

    def __init__(self) -> None:
        display_config = MultiAIDisplayConfig( initial=PARTICIPATING_MODELS )
        self.model_viewer = MultiAIModelViewer(display_config)
        self.judge_view = MultiAIJudgeResultView()
        self.judge_ai = JudgeAI()

    # ===== ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: models ãŒç„¡ã„ã¨ãè‡ªåŠ›ã§çµ„ã¿ç«‹ã¦ã‚‹ =====
    def _fallback_models_from_state(
        self,
        llm_meta: Dict[str, Any],
    ) -> Optional[Dict[str, Any]]:
        """
        llm_meta["models"] ãŒå­˜åœ¨ã—ãªã„ã¨ãã€
        st.session_state["messages"] ã‹ã‚‰æœ€å¾Œã® assistant ç™ºè¨€ã‚’æ‹¾ã£ã¦
        GPT-4o ã®ä»® models ã‚’ä½œã‚‹ã€‚

        ã“ã‚Œã¯ã€Œã¨ã‚Šã‚ãˆãšè£ç”»é¢ã§ä¸­èº«ã‚’è¦‹ãŸã„ã€ãŸã‚ã®ä¿é™ºã€‚
        æœ¬å‘½ã¯ conversation_engine.py å´ã§ models ã‚’è©°ã‚ã‚‹ã“ã¨ã€‚
        """
        try:
            messages: List[Dict[str, str]] = st.session_state.get("messages", [])
            last_assistant = None
            for m in reversed(messages):
                if m.get("role") == "assistant":
                    last_assistant = m.get("content", "")
                    break

            if not last_assistant:
                return None

            usage_main = llm_meta.get("usage_main") or llm_meta.get("usage") or {}

            models = {
                "gpt4o": {
                    "reply": last_assistant,
                    "usage": usage_main,
                    "route": llm_meta.get("route", "gpt"),
                    "model_name": llm_meta.get("model_main", "gpt-4o"),
                }
            }
            return models
        except Exception:
            return None

# components/multi_ai_response.py ã®ä¸­

class MultiAIResponse:
    ...

    def _ensure_models(self, llm_meta: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        models = llm_meta.get("models")
        if isinstance(models, dict) and models:
            return models
        return None
            
    def _ensure_judge(self, llm_meta: Dict[str, Any]) -> Dict[str, Any]:
        """
        llm_meta ã®çŠ¶æ…‹ã‚’è¦‹ã¦ã€å¿…è¦ã§ã‚ã‚Œã° JudgeAI ã‚’å®Ÿè¡Œã—ã€
        llm_meta["judge"] ã‚’åŸ‹ã‚ã¦è¿”ã™ã€‚
        """
        if not isinstance(llm_meta, dict):
            return {"winner": None, "reason": "llm_meta not available"}
    
        # æ—¢ã« judge ãŒ dict ã§å­˜åœ¨ã™ã‚Œã°ãã®ã¾ã¾ä½¿ã†
        judge = llm_meta.get("judge")
        if isinstance(judge, dict):
            return judge
    
        # models ãŒç„¡ã„ or å°‘ãªã‘ã‚Œã°åˆ¤å®šã§ããªã„
        models = llm_meta.get("models")
        if not isinstance(models, dict) or len(models) < 2:
            return {
                "winner": None,
                "reason": "æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚",
                "score_diff": 0.0,
            }
    
        # ã“ã“ã§åˆã‚ã¦åˆ¤å®šå®Ÿè¡Œ
        try:
            judge = self.judge_ai.run(llm_meta)
            return judge if isinstance(judge, dict) else {
                "winner": None,
                "reason": "JudgeAI returned invalid data.",
                "score_diff": 0.0,
            }
        except Exception as e:
            return {
                "winner": None,
                "reason": f"JudgeAI å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}",
                "score_diff": 0.0,
            }

    def render(self, llm_meta: Optional[Dict[str, Any]]) -> None:
        if not isinstance(llm_meta, dict) or not llm_meta:
            st.caption("ï¼ˆã¾ã ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        st.markdown("### âœ’ï¸ ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        ...

        # ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ
        models = self._ensure_models(llm_meta)
        if models:
            with st.expander("ğŸ¤ ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ", expanded=True):
                self.model_viewer.render(models)
        else:
            st.caption("ï¼ˆmodels æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")

        # Judge
        judge = self._ensure_judge(llm_meta)
        with st.expander("âš–ï¸ ãƒãƒ«ãƒAIå¯©è­°çµæœ", expanded=True):
            self.judge_view.render(judge)
